{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영양제공코드분석중.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohyunyang/MyStudy/blob/master/%EC%98%81%EC%96%91%EC%A0%9C%EA%B3%B5%EC%BD%94%EB%93%9C%EB%B6%84%EC%84%9D%EC%A4%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Isolation Forest\" 모델 사용\n",
        "001 feature 골라서 사용하면서 + pca 사용하여 최고점수 도출시도\n",
        "\n",
        "002 코사인, 피어슨 유사도 특성추가\n",
        "\n",
        "003 -\n",
        "\n",
        "004 Isolation Forest가 Robust모델에 비해 f1, auc 스코어 간의 격차가 적어 hyperparameter값 세부조정 시도\n",
        "\n",
        "- Isolation Forest h-params는 nes=150근처 pca는 사용하지 않을 때 성능이 가장 좋았다. -> 최대한 독립적인 특성만 사용하면서 학습시켰기 때문이라고 생각\n",
        "\n",
        "005 성능 개선을 위해서는 특성추가가 필요하다고 생각 11, 12, 17에서\n",
        "2, 4, 9, 10, 11, 12, 16, 17, 18 으로 특성 늘려서 학습\n",
        "\n"
      ],
      "metadata": {
        "id": "GBTAnPQrEW7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlHtVtnQECWj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import permutations,combinations #특성의 조합을 구하기 위한 import\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "\n",
        "import math #차후 factorial 계산 등 수학적인 계산을 위한 import\n",
        "from numpy import dot #코사인 유사도 및 피어슨 유사도 구할 때 numpy 계산을 위한 import\n",
        "from numpy.linalg import norm #위와 동일\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import PolynomialFeatures #특성공학을 사용하기 위한 import\n",
        "from sklearn.preprocessing import StandardScaler #전처리된 데이터들의 scale을 맞춰주기 위한 import\n",
        "from sklearn.decomposition import PCA #차원 축소 - 주성분의 개수에 따른 최적화 모델 구현을 위한 import\n",
        "\n",
        "\n",
        "\n",
        "#model\n",
        "from sklearn import svm\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.cluster import KMeans\n",
        "# from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score#점수산출용\n",
        "from sklearn.metrics import f1_score#점수산출용\n",
        "from sklearn.metrics import classification_report#점수산출용\n",
        "from sklearn.metrics import accuracy_score #이후 test.csv 파일의 predict 자료의 score을 매기기 위한 import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEoRrQIuwVPJ",
        "outputId": "c4fceddd-6ed3-4b91-b260-91c2dbdeae00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset은 Label이 존재하지 않음\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project_cfr/train.csv\")\n",
        "val_df  = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project_cfr/val.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project_cfr/test.csv\")\n",
        "submit = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project_cfr/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "JRnMJVzsEIU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단, Test Dataset이 포함된 데이터로 사전 학습된 모델 사용 금지\n",
        "\n",
        "대회 제공 데이터 이외의 외부데이터 사용 금지\n",
        "\n",
        "대회 제공 데이터 중 Train Dataset (train.csv)만 모델 학습에 사용 가능\n",
        "\n",
        "대회 제공 데이터 중 Validation Dataset (validation.csv)은 모델 학습에 사용은 불가능하지만 데이터 통계 정보와 모델 평가에는 사용 가능\n",
        "\n",
        "대회 제공 데이터 중 Test Dataset (test.csv)은 리더보드 제출을 위한 추론에만 사용 가능 (모델 학습 사용 불가능)"
      ],
      "metadata": {
        "id": "hT1XL-I4PKzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head(1))\n",
        "print('--------------------------------------')\n",
        "print(test_df.head(1))\n",
        "print('--------------------------------------')\n",
        "print(val_df.head(1))\n",
        "print('--------------------------------------')\n",
        "print(submit.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orJdCm-OR0I",
        "outputId": "42428195-7590-4a37-d3fd-a683ff484539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID        V1        V2        V3       V4        V5        V6        V7  \\\n",
            "0   3 -1.358354 -1.340163  1.773209  0.37978 -0.503198  1.800499  0.791461   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "\n",
            "        V26       V27       V28       V29       V30  \n",
            "0 -0.139097 -0.055353 -0.059752  4.983721 -0.994972  \n",
            "\n",
            "[1 rows x 31 columns]\n",
            "--------------------------------------\n",
            "        ID        V1        V2        V3        V4        V5        V6  \\\n",
            "0  AAAA0x1 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
            "\n",
            "        V25       V26       V27       V28       V29       V30  \n",
            "0  0.128539 -0.189115  0.133558 -0.021053  1.783274 -0.994983  \n",
            "\n",
            "[1 rows x 31 columns]\n",
            "--------------------------------------\n",
            "   ID        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0  10 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
            "\n",
            "         V8        V9  ...       V22       V23      V24       V25       V26  \\\n",
            "0  0.069539 -0.736727  ... -0.633753 -0.120794 -0.38505 -0.069733  0.094199   \n",
            "\n",
            "        V27       V28       V29       V30  Class  \n",
            "0  0.246219  0.083076 -0.255991 -0.994878      0  \n",
            "\n",
            "[1 rows x 32 columns]\n",
            "--------------------------------------\n",
            "        ID  Class\n",
            "0  AAAA0x1      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clist = list(train_df.columns)\n",
        "print(clist)\n",
        "\n",
        "train_data = train_df[clist[1:]].to_numpy()\n",
        "val_data = val_df[clist[1:]].to_numpy()\n",
        "val_target = val_df['Class'].to_numpy()\n",
        "\n",
        "print(val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZJiZLavELjX",
        "outputId": "bc461ca0-e2ff-4ec8-93df-69bfbc7a8ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30']\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "valcount1=0\n",
        "valcountm1=0\n",
        "for i in val_target:\n",
        "  if i==1:\n",
        "    valcount1+=1\n",
        "  else:\n",
        "    valcountm1+=1\n",
        "\n",
        "print(valcount1, valcountm1)\n",
        "\n",
        "outliers_fraction = valcount1/(valcount1+valcountm1)\n",
        "print(\"outliers_fraction =\",outliers_fraction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-dOnP5mUA0q",
        "outputId": "6fd23e78-eeaa-456d-ad39-f90e6f97c08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 28432\n",
            "outliers_fraction = 0.0010540369615627855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코사인유사도 구하기"
      ],
      "metadata": {
        "id": "etI6DUKsKUG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증데이터 중 사기인 것들 안에서 V1-V30 까지\n",
        "val_abnor = val_df[val_df['Class']==1][clist[1:]]\n",
        "print(val_abnor[:2])\n",
        "print(\"-----------------------\")\n",
        "\n",
        "#\n",
        "abnor_vector = val_abnor.mean().to_numpy()\n",
        "print(abnor_vector)"
      ],
      "metadata": {
        "id": "PtAsOqdALGZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f92006-534c-4eb4-cc06-9b57734bcef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           V1        V2        V3        V4        V5        V6        V7  \\\n",
            "71  -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
            "641  0.316459  3.809076 -5.615159  6.047445  1.554026 -2.651353 -0.746579   \n",
            "\n",
            "           V8        V9       V10  ...       V21       V22       V23  \\\n",
            "71  -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966   \n",
            "641  0.055586 -2.678679 -4.959493  ...  0.208828 -0.511747 -0.583813   \n",
            "\n",
            "          V24       V25       V26       V27       V28       V29       V30  \n",
            "71  -0.293803  0.279798 -0.145362 -0.252773  0.035764  7.084469 -0.989438  \n",
            "641 -0.219845  1.474753  0.491192  0.518868  0.402528 -0.293440 -0.906272  \n",
            "\n",
            "[2 rows x 30 columns]\n",
            "-----------------------\n",
            "[-6.4902307   4.78656835 -9.80242181  5.45855983 -4.61786208 -1.83473187\n",
            " -7.69930106  1.31215119 -3.31825355 -7.57510465  4.45015242 -7.29492844\n",
            "  0.05961486 -7.81510871 -0.26495949 -4.50606623 -7.33768492 -2.45956389\n",
            "  0.60334874  0.35844264 -0.02350577  0.37863818  0.0922817  -0.18676671\n",
            " -0.05566942  0.08068009 -0.52392903 -0.1703425   0.74247188 -0.06012367]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim(a, b):\n",
        "  return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "def cosfeature(data):\n",
        "  datacs=[]\n",
        "  for i in data[clist[1:]].to_numpy():\n",
        "    datacs.append(cos_sim(abnor_vector, i))\n",
        "  data['V31']=datacs\n",
        "\n",
        "cosfeature(train_df)\n",
        "cosfeature(val_df)\n",
        "cosfeature(test_df)"
      ],
      "metadata": {
        "id": "zqlARSPQVeI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "피어슨유사도 구하기 - 찾아보귕^^"
      ],
      "metadata": {
        "id": "bYm4ee1x3YTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_similarity(a, b):\n",
        "    return np.dot((a - np.mean(a)), (b - np.mean(b))) / ((np.linalg.norm(a - np.mean(a))) * (np.linalg.norm(b - np.mean(b))))\n",
        "\n",
        "def pearsonfeature(data):\n",
        "  datacs=[]\n",
        "  for i in data[clist[1:]].to_numpy():\n",
        "    datacs.append(pearson_similarity(abnor_vector, i))\n",
        "  data['V32']=datacs\n",
        "\n",
        "pearsonfeature(train_df)\n",
        "pearsonfeature(val_df)\n",
        "pearsonfeature(test_df)\n",
        "\n",
        "clist = list(train_df.columns)"
      ],
      "metadata": {
        "id": "1ibefjok3aJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clist))\n",
        "print(clist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FrxVSnmPsS6",
        "outputId": "585f5433-e1cb-4212-bfa9-113166eac1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n",
            "['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col=[clist[i] for i in [11, 12, 17, 31, 32]]\n",
        "print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oihTa9LOEOdg",
        "outputId": "4e68db60-12a7-48ce-b4f7-69e3d8c96f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['V11', 'V12', 'V17', 'V31', 'V32']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ID 를 제외한 특성 불러오기 함수\n",
        "def predata(data):\n",
        "  return data.drop(columns=['ID'])[col] \n",
        "\n",
        "\n",
        "def get_pred_label(model_pred): # val_pred 이 들어간다면??  # val_pred = m.predict(val_pca) 즉, \"model_rc로 차원축소한 val 데이터\"를 넣는다면? # val_pred 는 차원축소한 val데이터를 rc모델로 예측한 값들이 들어가 있다.\n",
        "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
        "    model_pred = np.where(model_pred == 1, 0, model_pred)  # np.where() 은 조건을 만족하는 위치의 인덱스를 가져옴\n",
        "    model_pred = np.where(model_pred == -1, 1, model_pred) # np.where(a조건,b,c) a조건이면 b, 그렇지 않으면 c의 인덱스를 가져옴 \n",
        "    return model_pred\n",
        "\n",
        "\n",
        "train_x = predata(train_df) # train_df['V11','V12','V17','V31','V32']\n",
        "print(train_x[:5])\n",
        "print(\"-----------------\")\n",
        "\n",
        "val_x = predata(val_df) # Input Data\n",
        "val_y = val_df['Class'] # Label\n",
        "print(val_x[:1])\n",
        "print(val_y[:1])\n",
        "\n",
        "test_x = predata(test_df)\n",
        "print(test_x[:1])\n",
        "print(col)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7zl1449X4hf",
        "outputId": "6bf6ec89-76d6-453d-f4de-fbda8315010f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        V11       V12       V17       V31       V32\n",
            "0  0.624501  0.066084  1.109969 -0.026012  0.024835\n",
            "1 -0.226487  0.178228 -0.684093 -0.090965 -0.136051\n",
            "2  1.341262  0.359894 -0.058133 -0.045050  0.001014\n",
            "3 -0.619468  0.291474 -1.222127 -0.108131 -0.144766\n",
            "4 -0.705117 -0.110452 -0.499768 -0.059377  0.015230\n",
            "-----------------\n",
            "        V11      V12      V17       V31       V32\n",
            "0  1.017614  0.83639 -0.54098 -0.055663  0.020418\n",
            "0    0\n",
            "Name: Class, dtype: int64\n",
            "      V11       V12       V17       V31       V32\n",
            "0 -0.5516 -0.617801  0.207971 -0.052446  0.015425\n",
            "['V11', 'V12', 'V17', 'V31', 'V32']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pSwRkqMsEVcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rc모델만 학습\n",
        "\n",
        "# for i in range(2, len())\n",
        "scoreboard={}\n",
        "th_score=0.88 #제출 파일 저장 문턱점수 \n",
        "maxscore=0.88 #지난회차 최고점수\n",
        "testname=\"002\"\n",
        "poly_dim =1\n",
        "\n",
        "for i in range(4, len(col)+1):  # range(4,6) i = 4 , 5\n",
        "  # 스케일 학습 후 적용\n",
        "  ss = StandardScaler()\n",
        "  ss.fit(train_x)\n",
        "  train_x = ss.transform(train_x)\n",
        "  val_x = ss.transform(val_x)\n",
        "  test_x = ss.transform(test_x)\n",
        "  # PCA 학습 후 적용 \n",
        "  pca = PCA(n_components = i)\n",
        "  pca.fit(train_x)\n",
        "  train_pca = pca.transform(train_x)\n",
        "  val_pca = pca.transform(val_x)\n",
        "  test_pca = pca.transform(test_x)\n",
        "\n",
        "  # anomaly_algorithms = [(\"Robust covariance\", EllipticEnvelope(contamination=outliers_fraction)),\n",
        "  #                     (\"One-Class SVM\", svm.OneClassSVM(nu=outliers_fraction, kernel=\"rbf\",gamma=0.1)),\n",
        "  #                     (\"Isolation Forest\", IsolationForest(max_samples=len(train_pca), contamination=outliers_fraction,random_state=42)),\n",
        "  #                     (\"Local Outlier Factor\", LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction))]\n",
        "\n",
        "  contamination_controlnumber=0\n",
        "  \n",
        "  # model_if = IsolationForest(n_estimators=nes, max_samples=len(train_pca), contamination=outliers_fraction, random_state=42, warm_start=True, verbose=0)\n",
        "  # model_ocs = svm.OneClassSVM(nu=outliers_fraction, kernel=\"rbf\",gamma=10)\n",
        "  model_rc = EllipticEnvelope(contamination=outliers_fraction + contamination_controlnumber) # 가우스 분산 데이터 세트에서 특이 치를 탐지하기위한 객체\n",
        "  # model_lof = LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction)\n",
        "  # (\"One-Class SVM\",model_ocs) (\"Isolation Forest\", model_if),\n",
        "  model_list=[ (\"Robust covariance\", model_rc) ]\n",
        "  for name, m in model_list: # m 은 model_re 모델\n",
        "    m.fit(train_pca)\n",
        "\n",
        "    val_pred = m.predict(val_pca) # model prediction # val_pred 는 차원축소한 val데이터를 rc모델로 예측한 값들이 들어가 있다.\n",
        "    val_pred = get_pred_label(val_pred) # 위 정의된 함수로 돌리면 이상치들은 사기(1) 정상(0)으로 분류가 진행됨\n",
        "    print(\"1번\",val_pred) ##\n",
        "\n",
        "    val_score = f1_score(val_y, val_pred, average='macro') # (val 타겟 값, 모델로 예측해서 라벨링된 타겟값, average='macro'?)\n",
        "    val_auc_score = roc_auc_score(val_y, val_pred)\n",
        "    scoreboard[\"model:{}, pca-ncom:{}, contamination:{}\".format(name, i, outliers_fraction + contamination_controlnumber)]=\\ # outliers_fraction + contamination_controlnumber ?? 이게뭐지\n",
        "    \"f1-score : {}, auc-score : {}\".format(round(val_score, 4)*100, round(val_auc_score, 4)*100)\n",
        "\n",
        "    if val_score>maxscore:\n",
        "      print(\"!!max score!!\")\n",
        "\n",
        "    if name == \"Isolation Forest\":\n",
        "      print('model:{}, pca-ncom:{}, n-esti:{}, contamination:{}'.format(name, i, nes, outliers_fraction + contamination_controlnumber),'\\n',\n",
        "          'f1-score : {},\\t\\tauc-score : {}'.format(round(val_score, 4)*100, round(val_auc_score, 4)*100))\n",
        "      \n",
        "    else:\n",
        "      print('model:{}, pca-ncom:{}, contamination:{}'.format(name, i, outliers_fraction + contamination_controlnumber),'\\n',\n",
        "          'f1-score : {},\\t\\tauc-score : {}'.format(round(val_score, 4)*100, round(val_auc_score, 4)*100))\n",
        "      \n",
        "      \n",
        "    # print(f'Validation F1 Score : [{val_score}]')\n",
        "    # print(classification_report(val_y, val_pred))\n",
        "    print()\n",
        "\n",
        "# 문턱점수 넘으면 자동으로 저장\n",
        "  if val_score>th_score:\n",
        "    test_pred = m.predict(test_pca) # model prediction  \n",
        "    test_pred = get_pred_label(test_pred)\n",
        "    submit['Class'] = test_pred\n",
        "    submit.to_csv('./submit{}_model_{}_ncom{}.csv'.format(testname, name, i), index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3u9AICFR3uG",
        "outputId": "0a1e5e74-3295-432c-ad4e-1e6d4bf18051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "!!max score!!\n",
            "model:Robust covariance, pca-ncom:4, contamination:0.0010540369615627855 \n",
            " f1-score : 89.28,\t\tauc-score : 86.66\n",
            "\n",
            "[0 0 0 ... 0 0 0]\n",
            "!!max score!!\n",
            "model:Robust covariance, pca-ncom:5, contamination:0.0010540369615627855 \n",
            " f1-score : 88.59,\t\tauc-score : 86.66\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def predata(data):\n",
        "  return data.drop(columns=['ID'])[col]\n",
        "\n",
        "def get_pred_label(model_pred):\n",
        "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
        "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
        "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
        "    return model_pred\n",
        "\n",
        "scoreboard={} #모델 별 점수 값 저장을 위한 딕셔너리 저장공간\n",
        "maxscoreboard=[] #제일 좋았던 모델 별 점수 젖장을 위한 저장공간\n",
        "th_score=0.88 #제출 파일 저장 문턱점수 \n",
        "maxscore=0 #지난회차 최고점수\n",
        "testname=\"003\"\n",
        "poly_dim =1\n",
        "testnum = 0\n",
        "\n",
        "for k in range(1, 6):\n",
        "  for ctu in list(combinations([4,9,10,16,18], k)): #k값에 따라서 몇개 뽑을지 결정\n",
        "     \n",
        "    col = [clist[i] for i in [11,12,17,31,32]+list(ctu)] # col 내가 뽑은 특성들이 들어 있는 list\n",
        "    \n",
        "    train_x = predata(train_df)\n",
        "    val_x = predata(val_df) # Input Data\n",
        "    val_y = val_df['Class'] # Label\n",
        "    test_x = predata(test_df)  \n",
        "\n",
        "    for i in range(len(col)-2, len(col)+1): #특성 개수 => len(col)\n",
        "      ss = StandardScaler()\n",
        "      ss.fit(train_x)\n",
        "      train_x = ss.transform(train_x)\n",
        "      val_x = ss.transform(val_x)\n",
        "      test_x = ss.transform(test_x)\n",
        "\n",
        "      pca = PCA(n_components = i) #i값에 따라 pca 주성분 개수 결정\n",
        "      pca.fit(train_x)\n",
        "      train_pca = pca.transform(train_x)\n",
        "      val_pca = pca.transform(val_x)\n",
        "      test_pca = pca.transform(test_x)\n",
        "\n",
        "      contamination_controlnumber=0 #확률 조정 변수\n",
        "      nes=150 # Isolation Forest n_esti 값 조정하기 위한 변수\n",
        "\n",
        "\n",
        "      model_if = IsolationForest(n_estimators=nes, max_samples=len(train_pca), contamination=outliers_fraction, random_state=42, verbose=0)\n",
        "      # model_ocs = svm.OneClassSVM(nu=outliers_fraction, kernel=\"rbf\",gamma=10)\n",
        "      model_rc = EllipticEnvelope(contamination=outliers_fraction + contamination_controlnumber)\n",
        "      # model_lof = LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction)\n",
        "      # (\"One-Class SVM\",model_ocs) \n",
        "      model_list=[(\"Isolation Forest\", model_if), (\"Robust covariance\", model_rc) ]\n",
        "      for name, m in model_list:\n",
        "        testnum+=1\n",
        "        m.fit(train_pca)\n",
        "\n",
        "        val_pred = m.predict(val_pca) # model prediction\n",
        "        val_pred = get_pred_label(val_pred)\n",
        "        val_score = f1_score(val_y, val_pred, average='macro')\n",
        "        val_auc_score = roc_auc_score(val_y, val_pred)\n",
        "        scoreboard[\"model:{}, pca-ncom:{}, contamination:{}\".format(name, i, outliers_fraction + contamination_controlnumber)]=\\\n",
        "        \"f1-score : {}, auc-score : {}\".format(round(val_score, 4)*100, round(val_auc_score, 4)*100)\n",
        "\n",
        "        if val_score >= maxscore:\n",
        "          maxscore = val_score\n",
        "          maxscoreboard.append(\"no.{}-f1-score:{},\\t\\t auc-score:{}\".format(testnum, val_score, val_auc_score))\n",
        "\n",
        "          print(\"----------------------------------------------------\")\n",
        "          print(\"!!!!!!!!!!!!!!!!!!!!!max score!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "          print(\"----------------------------------------------------\")\n",
        "        \n",
        "        print(\"no.{} model_{} ------------ feature:{}, k:{}\".format(testnum, name, col, k))\n",
        "        \n",
        "        if name == \"Isolation Forest\":\n",
        "          print('pca-ncom:{}, n-esti:{}, contamination:{}'.format(i, nes, outliers_fraction + contamination_controlnumber),'\\n',\n",
        "              'f1-score : {},\\t\\tauc-score : {}'.format(round(val_score, 4)*100, round(val_auc_score, 4)*100))\n",
        "          \n",
        "        else:\n",
        "          print('pca-ncom:{}, contamination:{}'.format(i, outliers_fraction + contamination_controlnumber),'\\n',\n",
        "              'f1-score : {},\\t\\tauc-score : {}'.format(round(val_score, 4)*100, round(val_auc_score, 4)*100))\n",
        "          \n",
        "          \n",
        "        # print(f'Validation F1 Score : [{val_score}]')\n",
        "        # print(classification_report(val_y, val_pred))\n",
        "        print()\n",
        "\n",
        "      if val_score>th_score:\n",
        "        test_pred = m.predict(test_pca) # model prediction  \n",
        "        test_pred = get_pred_label(test_pred)\n",
        "        submit['Class'] = test_pred\n",
        "        submit.to_csv('./submit{}_no.{}_model_{}.csv'.format(testname, testnum, name), index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "hAk3cqMAc0Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(combinations([4,9,10,16,18], 3))"
      ],
      "metadata": {
        "id": "2sk1XpCRd1uJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}