{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfacebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9714db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./flp/traintry001/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9788eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width:   175\n",
      "height:  287\n",
      "channel: 3\n"
     ]
    }
   ],
   "source": [
    "# 삼분할법에 대한 점수계산 코드\n",
    "\n",
    "#각 이미지에 대한 크기 반환\n",
    "h, w, c = image.shape\n",
    "print('width:  ', w)\n",
    "print('height: ', h)\n",
    "print('channel:', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f616cfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41328bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1, x2: 58, 116\n",
      "y1, y2: 95, 191\n"
     ]
    }
   ],
   "source": [
    "#method1 \n",
    "\n",
    "#삼분할관련 교차지점 point 반환 ->p1,p2,p3,p4\n",
    "\n",
    "x1, x2 = w//3, w*2//3\n",
    "y1, y2 = h//3, h*2//3\n",
    "\n",
    "print(\"x1, x2: {}, {}\".format(x1, x2))\n",
    "print(\"y1, y2: {}, {}\".format(y1, y2))\n",
    "\n",
    "p1 = [x1, y1]\n",
    "p2 = [x1, y2]\n",
    "p3 = [x2, y1]\n",
    "p4 = [x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a075d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_d(p,n):\n",
    "    d = (p[0]-n[0])**2 + (p[1]-n[1])**2\n",
    "    return d**(1/2) \n",
    "\n",
    "def cal_p(x,y):\n",
    "    return (x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b2416a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136.12629175186157, 34.94397783279419]\n",
      "60.254120154104406\n",
      "0.4555770407828514\n"
     ]
    }
   ],
   "source": [
    "#사진상 사람의 코 위치 검출\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# For static images:\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=True,\n",
    "    refine_face_landmarks=True) as holistic:\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    #이미지상에 랜드마크가 찍히면\n",
    "    if results.pose_landmarks:\n",
    "        pnx = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * w\n",
    "        pny = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * h\n",
    "        pn = [pnx, pny]\n",
    "        print(pn)\n",
    "        #pn-> 코의 위치\n",
    "    \n",
    "    plist = [p1, p2, p3, p4]\n",
    "    #pnd = point to nose distance\n",
    "    pnd= min(cal_d(p1, pn), cal_d(p2, pn), cal_d(p3, pn), cal_d(p4, pn))\n",
    "    print(pnd)\n",
    "    r = cal_d([0,0], p1)\n",
    "    \n",
    "    score1 = (r - pnd)/(r)\n",
    "    print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28fc11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "\n",
    "#주요면적 크기\n",
    "\n",
    "BG_COLOR = (255, 255, 255) # gray\n",
    "MASK_COLOR = (1, 1, 1) # white\n",
    "annotated_image = image.copy()\n",
    "\n",
    "condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "bg_image[:] = BG_COLOR\n",
    "annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "\n",
    "cv2.imshow(\"annotated_image\", annotated_image)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f7af72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8909143\n"
     ]
    }
   ],
   "source": [
    "count000=0\n",
    "for i in annotated_image:\n",
    "    ic0=i.tolist()\n",
    "    count000 += ic0.count([255,255,255])\n",
    "print(count000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d00d67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7306907668545813\n",
      "0.16930923314541865\n",
      "0.263872899367745\n",
      "0.5047994739227235\n"
     ]
    }
   ],
   "source": [
    "print(count000/(w*h))\n",
    "portion = 1- count000/(w*h)\n",
    "\n",
    "minp = min(abs(0.1-portion), abs(0.56-portion), abs(0.82-portion))\n",
    "print(minp)\n",
    "\n",
    "\n",
    "if portion<0.82 and portion>0.1:\n",
    "    a=1/0.23\n",
    "    score2 = a*(0.23-minp)\n",
    "    \n",
    "elif portion>=0.82:\n",
    "    a=1/0.18\n",
    "    score2 = a*(0.18-minp)\n",
    "\n",
    "elif portion<=0.1:\n",
    "    a=1/0.1\n",
    "    score2 = a*(0.1-minp)\n",
    "    \n",
    "print(score2)\n",
    "\n",
    "print((score1+score2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d9c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8604f17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3041"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './flp/traindata_forrotation/'\n",
    "file_list = os.listdir(path)\n",
    "jpg_file_list = [file for file in file_list if file.endswith(\".jpg\")]\n",
    "len(jpg_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76ef1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6512cc8de23f4234898b33a3ba9929fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#사진상 사람의 코 위치 검출\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "BG_COLOR = (255, 255, 255) # gray\n",
    "MASK_COLOR = (1, 1, 1) # white\n",
    "\n",
    "photo_data = []\n",
    "IMAGE_FILES = jpg_file_list\n",
    "\n",
    "def cal_d(p,n):\n",
    "    d = (p[0]-n[0])**2 + (p[1]-n[1])**2\n",
    "    return d**(1/2) \n",
    "\n",
    "def cal_p(x,y):\n",
    "    return (x-y)\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=True,\n",
    "    refine_face_landmarks=True) as holistic:\n",
    "    idx=0\n",
    "    for file in tqdm(IMAGE_FILES):\n",
    "        image = cv2.imread('./flp/traindata_forrotation/'+file)\n",
    "#         image = cv2.imread('./0a.jpg')\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "#score1#\n",
    "# 삼분할법에 대한 점수계산 코드\n",
    "\n",
    "        #각 이미지에 대한 크기 반환\n",
    "        h, w, c = image.shape\n",
    "\n",
    "        #삼분할관련 교차지점 point 반환 ->p1,p2,p3,p4\n",
    "\n",
    "        x1, x2 = w//3, w*2//3\n",
    "        y1, y2 = h//3, h*2//3\n",
    "\n",
    "        p1 = [x1, y1]\n",
    "        p2 = [x1, y2]\n",
    "        p3 = [x2, y1]\n",
    "        p4 = [x2, y2]\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            pnx = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * w\n",
    "            pny = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * h\n",
    "            pn = [pnx, pny]\n",
    "            #pn-> 코의 위치\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        plist = [p1, p2, p3, p4]\n",
    "        #pnd = point to nose distance\n",
    "        pnd= min(cal_d(p1, pn), cal_d(p2, pn), cal_d(p3, pn), cal_d(p4, pn))\n",
    " \n",
    "        r = cal_d([0,0], p1)\n",
    "    \n",
    "        score1 = (r - pnd)/(r)\n",
    "\n",
    "########################################################################################################        \n",
    "\n",
    "#score2#\n",
    "#비율 점수계산 코드\n",
    "\n",
    "        # Draw segmentation on the image.\n",
    "        # To improve segmentation around boundaries, consider applying a joint\n",
    "        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
    "        annotated_image = image.copy()\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = BG_COLOR\n",
    "        annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "\n",
    "        count000=0\n",
    "        for i in annotated_image:\n",
    "            ic0=i.tolist()\n",
    "            count000 += ic0.count([255,255,255])\n",
    "\n",
    "        portion = 1- count000/(w*h)\n",
    "\n",
    "        minp = min(abs(0.1-portion), abs(0.56-portion), abs(0.82-portion))\n",
    "\n",
    "        if portion<0.82 and portion>0.1:\n",
    "            a=1/0.23\n",
    "            score2 = a*(0.23-minp)\n",
    "\n",
    "        elif portion>=0.82:\n",
    "            a=1/0.18\n",
    "            score2 = a*(0.18-minp)\n",
    "\n",
    "        elif portion<=0.1:\n",
    "            a=1/0.1\n",
    "            score2 = a*(0.1-minp)\n",
    "\n",
    "        score = (score1+score2)/2\n",
    "########################################################################################################\n",
    "\n",
    "#prepare data#\n",
    "\n",
    "        n=[]\n",
    "        for data_point in results.pose_landmarks.landmark:\n",
    "            n.append(data_point.x)\n",
    "            n.append(data_point.y)\n",
    "            n.append(data_point.z)\n",
    "        n.append(score)\n",
    "\n",
    "        photo_data.append(n)\n",
    "\n",
    "########################################################################################################\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1034de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2742"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(photo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf771e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('./flp/photo_scoredata001.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "writer.writerows(photo_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192df2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'mediapipe'",
   "language": "python",
   "name": "mediapipe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
