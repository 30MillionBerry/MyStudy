{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Basic_ANN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRbzN5zvB4gcMldPAanSEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohyunyang/MyStudy/blob/master/DL_Basic_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import scipy.special\n",
        "import matplotlib.pyplot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "class NeuralNetwork: # 클래스 만들기 = 과자틀 만들기\n",
        "    \n",
        "    \n",
        "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): # 자신, 입력노트, 은닉노드, 결과노드, 학습률\n",
        "       \n",
        "        self.inodes = inputnodes\n",
        "        self.hnodes = hiddennodes\n",
        "        self.onodes = outputnodes\n",
        "        \n",
        "        self.lr = learningrate\n",
        "\n",
        "\n",
        "    def training(self, input_list, target_list):\n",
        "\n",
        " \n",
        "    def test(self, input_list):\n",
        "\n",
        "\n",
        "input_nodes = 3\n",
        "hidden_nodes = 3\n",
        "output_nodes = 3\n",
        "\n",
        "learning_rate = 0.3\n",
        "\n",
        "n = NeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)    # 클래스 NeuralNetwork 를 n 변수에 저장\n",
        "\n"
      ],
      "metadata": {
        "id": "OqA0DTGNtM4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import scipy.special\n",
        "import matplotlib.pyplot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    \n",
        "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
        "       \n",
        "        self.inodes = inputnodes\n",
        "        self.hnodes = hiddennodes\n",
        "        self.onodes = outputnodes\n",
        "        #  math.pow(x, y) 함수는 x의 y 거듭제곱 // (x의 y승)을 반환  (지수가 분수면 분모루트, 분자는 지수로)\n",
        "        # np.random.normal(x,y,z) 설명 : np.random.normal(0,1,1000) # [정규분포] 평균 0, 표준편차 1, 개수 1000개\n",
        "        # 평균 0.0, 표준편차 pow(self.inodes, -0.5), rotn\n",
        "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))  # 입력 에서 히든으로 가는 가중치\n",
        "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))  # 히든 에서 아웃풋으로 가는 가중치\n",
        "\n",
        "        self.lr = learningrate\n",
        "        \n",
        "        self.activation_function = lambda x: scipy.special.expit(x) # 시그모이드 함수 : scipy.special.expit(x)\n",
        "        \n",
        "    \n",
        "    def training(self, input_list, target_list):\n",
        "        \n",
        "    \n",
        "    def test(self, input_list):\n",
        "        \n",
        "        input = numpy.array(input_list, ndmin=2).T   # ndmin = 2는 1차원 배열을 2차원 배열로, T는 전치행렬로 바꾸기\n",
        "       \n",
        "        hidden_input = numpy.dot(self.wih, input)  # 행렬곱 : numpy.dot // wih * input\n",
        "        \n",
        "        hidden_output = self.activation_function(hidden_input)  # 히든레이어의 아웃풋은 wih * input 을 활성함수를 통과 시킨 값\n",
        "        \n",
        "        \n",
        "        final_input = numpy.dot(self.who, hidden_output)\n",
        "        \n",
        "        final_output = self.activation_function(final_input)\n",
        "        \n",
        "        return final_output\n",
        "\n"
      ],
      "metadata": {
        "id": "0ElD4CT8tMve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppmfkZKXtCpy"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import scipy.special\n",
        "import matplotlib.pyplot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    \n",
        "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
        "       \n",
        "        self.inodes = inputnodes\n",
        "        self.hnodes = hiddennodes\n",
        "        self.onodes = outputnodes\n",
        "        \n",
        "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
        "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
        "\n",
        "        self.lr = learningrate\n",
        "        \n",
        "        self.activation_function = lambda x: scipy.special.expit(x)\n",
        "        \n",
        "    \n",
        "    def training(self, input_list, target_list):\n",
        "       \n",
        "        input = numpy.array(input_list, ndmin=2).T\n",
        "        target = numpy.array(target_list, ndmin=2).T\n",
        "        \n",
        "     \n",
        "        hidden_input = numpy.dot(self.wih, input)\n",
        "       \n",
        "        hidden_output = self.activation_function(hidden_input)\n",
        "        \n",
        "        \n",
        "        final_input = numpy.dot(self.who, hidden_output)\n",
        "        \n",
        "        final_output = self.activation_function(final_input)\n",
        "        \n",
        "       \n",
        "        output_error = target - final_output\n",
        "        \n",
        "        hidden_error = numpy.dot(self.who.T, output_error) \n",
        "        \n",
        "        \n",
        "        self.who += self.lr * numpy.dot((output_error * final_output * (1.0 - final_output)), numpy.transpose(hidden_output))\n",
        "\n",
        "        self.wih += self.lr * numpy.dot((hidden_error * hidden_output * (1.0 - hidden_output)), numpy.transpose(input))\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "   \n",
        "    def test(self, input_list):\n",
        "        \n",
        "        input = numpy.array(input_list, ndmin=2).T\n",
        "       \n",
        "        hidden_input = numpy.dot(self.wih, input)\n",
        "        \n",
        "        hidden_output = self.activation_function(hidden_input)\n",
        "        \n",
        "        \n",
        "        final_input = numpy.dot(self.who, hidden_output)\n",
        "        \n",
        "        final_output = self.activation_function(final_input)\n",
        "        \n",
        "        return final_output"
      ]
    }
  ]
}